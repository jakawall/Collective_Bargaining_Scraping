{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "from lxml import etree\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--disable-search-engine-choice-screen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open page\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "driver.get(\"https://digital.oegbverlag.at/login?r=https%3A%2F%2Fdigital.oegbverlag.at%2Fkvsystem\")\n",
    "time.sleep(3)\n",
    "\n",
    "#for some reason I have to manually click on the \"reject cookies\" option, can't find a way to make the webdriver do it \n",
    "#select_element = driver.find_element(By.XPATH, '//*[@id=\"uc-center-container\"]/div[2]/div/div/div/div/button[2]')\n",
    "#select_element.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select \"für ögbverlag kunden\"\n",
    "element=WebDriverWait(driver, 10).until(EC. element_to_be_clickable((By.XPATH, \"/html/body/div[1]/div/div[2]/div/div[1]/div[3]/div[2]/button\")))\n",
    "select_element = driver.find_element(By.XPATH, '/html/body/div[1]/div/div[2]/div/div[1]/div[3]/div[2]/button')\n",
    "select_element.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#login\n",
    "username = driver.find_element(By.ID, \"username\")\n",
    "password = driver.find_element(By.ID, \"password\")\n",
    "\n",
    "username.send_keys(\"jakob.wall@econ.uzh.ch\")\n",
    "password.send_keys(\"D00rcityoverhere\")\n",
    "\n",
    "driver.find_element(By.ID, \"login\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select \"erweiterte Suche and search\"\n",
    "element=WebDriverWait(driver, 10).until(EC. element_to_be_clickable((By.XPATH, \"/html/body/div[1]/div/div[2]/div[1]/div[2]/div/div/div[2]\")))\n",
    "select_element = driver.find_element(By.XPATH, '/html/body/div[1]/div/div[2]/div[1]/div[2]/div/div/div[2]')\n",
    "select_element.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_years = []\n",
    "for year in range(1995,2022):\n",
    "    driver.get(\"https://digital.oegbverlag.at/kvsystem?q=&v=\"+str(year)+\"-01-01\")\n",
    "    #print(\"01.01.\" + str(year))\n",
    "\n",
    "    #select date\n",
    "    #date = driver.find_element(By.XPATH, \"/html/body/div[1]/div/div[2]/div[1]/div[2]/div/div[2]/div/div/div[1]/div[1]/div/div/div[2]/div/input\")\n",
    "    #date.send_keys(Keys.CONTROL + \"a\")\n",
    "    #date.send_keys(Keys.DELETE)\n",
    "    #date.send_keys(\"01.01.\" + str(year))\n",
    "\n",
    "    #search\n",
    "    element=WebDriverWait(driver, 30000000).until(EC. element_to_be_clickable((By.XPATH, \"/html/body/div[1]/div/div[2]/div/div[2]/div/div[1]/div[1]/div[1]/div/input\")))\n",
    "    searchbar = driver.find_element(By.XPATH, \"/html/body/div[1]/div/div[2]/div[1]/div[2]/div/div[1]/div[1]/div[1]/div/input\")\n",
    "    searchbar.send_keys(Keys.RETURN)\n",
    "\n",
    "    #I need to click on \"mehr anzeigen\" until the whole list is visible. \n",
    "    #Unfortunately, the site does not work perfectly, and keeps on displaying the button \"mehr anzeigen\" as a clickable element even though we are at the end. As a solution, I just clik 40 times, which is always enough\n",
    "    #  Unfortunately, the site does not work perf\n",
    "    #select \"mehr anzeigen\"\n",
    "    for i in range (40):\n",
    "        element=WebDriverWait(driver, 30000000).until(EC. element_to_be_clickable((By.XPATH, \"/html/body/div[1]/div/div[2]/div[2]/div/div[2]/button\")))\n",
    "        select_element = driver.find_element(By.XPATH, '/html/body/div[1]/div/div[2]/div[2]/div/div[2]/button')\n",
    "        select_element.click()\n",
    "        #need to wait a bit, otherwise the site doesn't respond\n",
    "        time.sleep(2)\n",
    "        print(i)\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "    links = soup.find_all('a')\n",
    "    # Create a list to store (text, link) tuples\n",
    "    result_list = []\n",
    "    # Loop through each <a> tag\n",
    "    for link in links:\n",
    "        # Get the href attribute (the link)\n",
    "        href = link.get('href')\n",
    "        \n",
    "        # Get the text inside the <span> (if any)\n",
    "        text = link.get_text().strip()  # .strip() removes any extra whitespace\n",
    "        \n",
    "        if href and text:\n",
    "            result_list.append((text, href))\n",
    "\n",
    "    # Filter the list to keep only elements where the link starts with \"/kvsystem\"\n",
    "    filtered_list = [(text, link) for text, link in result_list if link.startswith(\"/kvsystem/\")]\n",
    "\n",
    "    #append current year\n",
    "    all_years.append(filtered_list)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn list into pandas dataframe \n",
    "all_years_df = pd.DataFrame(columns = ['Text', 'Link', 'Year'])\n",
    "for i in range(len(all_years)):\n",
    "    df_current = pd.DataFrame(all_years[i], columns=['Text', 'Link'])\n",
    "    df_current['Year'] = 1995+i\n",
    "\n",
    "    all_years_df = pd.concat([all_years_df,df_current ], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save as csv\n",
    "all_years_df.to_csv('./data/kv_links_all_years.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#load csv and sort\n",
    "all_years_df = pd.read_csv('./data/kv_links_all_years.csv')\n",
    "all_years_df = all_years_df.sort_values('Text')\n",
    "all_years_df = all_years_df.reset_index(drop=True)\n",
    "all_years_df = all_years_df.drop(columns =['Unnamed: 0'])\n",
    "\n",
    "#ignore zusatz kvs\n",
    "all_years_df = all_years_df[~all_years_df['Text'].str.contains(\"ZKV\")]\n",
    "all_years_df = all_years_df.reset_index(drop=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#contracts_df = pd.DataFrame()\n",
    "contracts_df = pd.read_csv('./data/kv_contracts_all_years_8195.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15816\n",
      "15817\n",
      "15818\n",
      "15819\n",
      "15820\n",
      "15821\n",
      "15822\n",
      "15823\n",
      "15824\n",
      "15825\n",
      "15826\n",
      "15827\n",
      "15828\n",
      "15829\n",
      "15830\n",
      "15831\n",
      "15832\n",
      "15833\n",
      "15834\n",
      "15835\n",
      "15836\n",
      "15837\n",
      "15838\n",
      "15839\n",
      "15840\n",
      "15841\n",
      "15842\n",
      "15843\n",
      "15844\n",
      "15845\n",
      "15846\n",
      "15847\n",
      "15848\n",
      "15849\n",
      "15850\n",
      "15851\n",
      "15852\n",
      "15853\n",
      "15854\n",
      "15855\n",
      "15856\n",
      "15857\n",
      "15858\n",
      "15859\n",
      "15860\n",
      "15861\n",
      "15862\n",
      "15863\n",
      "15864\n",
      "15865\n",
      "15866\n",
      "15867\n",
      "15868\n",
      "15869\n",
      "15870\n",
      "15871\n",
      "15872\n",
      "15873\n",
      "15874\n",
      "15875\n",
      "15876\n",
      "15877\n",
      "15878\n",
      "15879\n",
      "15880\n",
      "15881\n",
      "15882\n",
      "15883\n",
      "15884\n",
      "15885\n",
      "15886\n",
      "15887\n",
      "15888\n",
      "15889\n",
      "15890\n",
      "15891\n",
      "15892\n",
      "15893\n",
      "15894\n",
      "15895\n",
      "15896\n",
      "15897\n",
      "15898\n",
      "15899\n",
      "15900\n",
      "15901\n",
      "15902\n",
      "15903\n",
      "15904\n",
      "15905\n",
      "15906\n",
      "15907\n",
      "15908\n",
      "15909\n",
      "15910\n",
      "15911\n",
      "15912\n",
      "15913\n",
      "15914\n",
      "15915\n",
      "15916\n",
      "15917\n",
      "15918\n",
      "15919\n",
      "15920\n",
      "15921\n",
      "15922\n",
      "15923\n",
      "15924\n",
      "15925\n",
      "15926\n",
      "15927\n",
      "15928\n",
      "15929\n",
      "15930\n",
      "15931\n",
      "15932\n",
      "15933\n",
      "15934\n",
      "15935\n",
      "15936\n",
      "15937\n",
      "15938\n",
      "15939\n",
      "15940\n",
      "15941\n",
      "15942\n",
      "15943\n",
      "15944\n",
      "15945\n",
      "15946\n",
      "15947\n",
      "15948\n",
      "15949\n",
      "15950\n",
      "15951\n",
      "15952\n",
      "15953\n",
      "15954\n",
      "15955\n",
      "15956\n",
      "15957\n",
      "15958\n",
      "15959\n",
      "15960\n",
      "15961\n",
      "15962\n",
      "15963\n",
      "15964\n",
      "15965\n",
      "15966\n",
      "15967\n",
      "15968\n",
      "15969\n",
      "15970\n",
      "15971\n",
      "15972\n",
      "15973\n",
      "15974\n",
      "15975\n",
      "15976\n",
      "15977\n",
      "15978\n",
      "15979\n",
      "15980\n",
      "15981\n",
      "15982\n",
      "15983\n",
      "15984\n",
      "15985\n",
      "15986\n",
      "15987\n",
      "15988\n",
      "15989\n",
      "15990\n",
      "15991\n",
      "15992\n",
      "15993\n",
      "15994\n",
      "15995\n",
      "15996\n",
      "15997\n",
      "15998\n",
      "15999\n",
      "16000\n",
      "16001\n",
      "16002\n",
      "16003\n",
      "16004\n",
      "16005\n",
      "16006\n",
      "16007\n",
      "16008\n",
      "16009\n",
      "16010\n",
      "16011\n",
      "16012\n",
      "16013\n",
      "16014\n",
      "16015\n",
      "16016\n",
      "16017\n",
      "16018\n",
      "16019\n",
      "16020\n",
      "16021\n",
      "16022\n",
      "16023\n",
      "16024\n",
      "16025\n",
      "16026\n",
      "16027\n",
      "16028\n",
      "16029\n",
      "16030\n",
      "16031\n",
      "16032\n",
      "16033\n",
      "16034\n",
      "16035\n",
      "16036\n",
      "16037\n",
      "16038\n",
      "16039\n",
      "16040\n",
      "16041\n",
      "16042\n",
      "16043\n",
      "16044\n",
      "16045\n",
      "16046\n",
      "16047\n",
      "16048\n",
      "16049\n",
      "16050\n",
      "16051\n",
      "16052\n",
      "16053\n",
      "16054\n",
      "16055\n",
      "16056\n",
      "16057\n",
      "16058\n",
      "16059\n",
      "16060\n",
      "16061\n",
      "16062\n",
      "16063\n",
      "16064\n",
      "16065\n",
      "16066\n",
      "16067\n",
      "16068\n",
      "16069\n",
      "16070\n",
      "16071\n",
      "16072\n",
      "16073\n",
      "16074\n",
      "16075\n",
      "16076\n",
      "16077\n",
      "16078\n",
      "16079\n",
      "16080\n",
      "16081\n",
      "16082\n",
      "16083\n",
      "16084\n",
      "16085\n",
      "16086\n",
      "16087\n",
      "16088\n",
      "16089\n",
      "16090\n",
      "16091\n",
      "16092\n",
      "16093\n",
      "16094\n",
      "16095\n",
      "16096\n",
      "16097\n",
      "16098\n",
      "16099\n",
      "16100\n",
      "16101\n",
      "16102\n",
      "16103\n",
      "16104\n",
      "16105\n",
      "16106\n",
      "16107\n",
      "16108\n",
      "16109\n",
      "16110\n",
      "16111\n",
      "16112\n",
      "16113\n",
      "16114\n",
      "16115\n",
      "16116\n",
      "16117\n",
      "16118\n",
      "16119\n",
      "16120\n",
      "16121\n",
      "16122\n",
      "16123\n",
      "16124\n",
      "16125\n",
      "16126\n",
      "16127\n",
      "16128\n",
      "16129\n",
      "16130\n",
      "16131\n",
      "16132\n",
      "16133\n",
      "16134\n",
      "16135\n",
      "16136\n",
      "16137\n",
      "16138\n",
      "16139\n",
      "16140\n",
      "16141\n",
      "16142\n",
      "16143\n",
      "16144\n",
      "16145\n",
      "16146\n",
      "16147\n",
      "16148\n",
      "16149\n",
      "16150\n",
      "16151\n",
      "16152\n",
      "16153\n",
      "16154\n",
      "16155\n",
      "16156\n",
      "16157\n",
      "16158\n",
      "16159\n",
      "16160\n",
      "16161\n",
      "16162\n",
      "16163\n",
      "16164\n",
      "16165\n",
      "16166\n",
      "16167\n",
      "16168\n",
      "16169\n",
      "16170\n",
      "16171\n",
      "16172\n",
      "16173\n",
      "16174\n",
      "16175\n",
      "16176\n",
      "16177\n",
      "16178\n",
      "16179\n",
      "16180\n",
      "16181\n",
      "16182\n",
      "16183\n",
      "16184\n",
      "16185\n",
      "16186\n",
      "16187\n",
      "16188\n",
      "16189\n",
      "16190\n",
      "16191\n",
      "16192\n",
      "16193\n",
      "16194\n",
      "16195\n",
      "16196\n",
      "16197\n",
      "16198\n",
      "16199\n",
      "16200\n",
      "16201\n",
      "16202\n",
      "16203\n",
      "16204\n",
      "16205\n",
      "16206\n",
      "16207\n",
      "16208\n",
      "16209\n",
      "16210\n",
      "16211\n",
      "16212\n",
      "16213\n",
      "16214\n",
      "16215\n",
      "16216\n",
      "16217\n",
      "16218\n",
      "16219\n",
      "16220\n",
      "16221\n",
      "16222\n",
      "16223\n",
      "16224\n",
      "16225\n",
      "16226\n",
      "16227\n",
      "16228\n",
      "16229\n",
      "16230\n",
      "16231\n",
      "16232\n",
      "16233\n",
      "16234\n",
      "16235\n",
      "16236\n",
      "16237\n",
      "16238\n",
      "16239\n",
      "16240\n",
      "16241\n",
      "16242\n",
      "16243\n",
      "16244\n",
      "16245\n",
      "16246\n",
      "16247\n",
      "16248\n",
      "16249\n",
      "16250\n",
      "16251\n",
      "16252\n",
      "16253\n",
      "16254\n",
      "16255\n",
      "16256\n",
      "16257\n",
      "16258\n",
      "16259\n",
      "16260\n",
      "16261\n",
      "16262\n",
      "16263\n",
      "16264\n",
      "16265\n",
      "16266\n",
      "16267\n",
      "16268\n",
      "16269\n",
      "16270\n",
      "16271\n",
      "16272\n",
      "16273\n",
      "16274\n",
      "16275\n",
      "16276\n",
      "16277\n",
      "16278\n",
      "16279\n"
     ]
    }
   ],
   "source": [
    "for i in range(15816,len(all_years_df)):\n",
    "    print(i)\n",
    "    link = str(\"https://digital.oegbverlag.at\" + all_years_df['Link'].iloc[i])\n",
    "\n",
    "    driver.get(link)\n",
    "    time.sleep(1.5)\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "    #check if we get a server error: if yes, we skip to the next link\n",
    "    is_server_error = 1 if \"Serverfehler\" in soup.title.string else 0\n",
    "    if is_server_error:\n",
    "        print(\"Server Error\")\n",
    "\n",
    "    else:\n",
    "        #'_c._d._e._f._h._av._al'\n",
    "        #'_go._p._c._d._e._ap._gn._i._bs'\n",
    "        element=WebDriverWait(driver, 300).until(EC. element_to_be_clickable((By.CLASS_NAME, '_c._d._e._f._h._av._al')))\n",
    "        xpath = \"//div[contains(concat(' ', normalize-space(@class), ' '), ' _c ') and contains(concat(' ', normalize-space(@class), ' '), ' _d ') and contains(concat(' ', normalize-space(@class), ' '), ' _e ')]/div[contains(concat(' ', normalize-space(@class), ' '), ' _c ') and contains(concat(' ', normalize-space(@class), ' '), ' _d ') and contains(concat(' ', normalize-space(@class), ' '), ' _e ') and contains(concat(' ', normalize-space(@class), ' '), ' _f ') and contains(concat(' ', normalize-space(@class), ' '), ' _h ') and contains(concat(' ', normalize-space(@class), ' '), ' _av ') and contains(concat(' ', normalize-space(@class), ' '), ' _al ')]\"\n",
    "        subcontracts = driver.find_elements(By.XPATH, xpath)\n",
    "        #subcontracts = driver.find_elements(By.CLASS_NAME, '_c._d._e._f._h._av._al')\n",
    "\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        css_selector = f\".{'_c._d._e'} > .{'_c._d._e._f._h._av._al'}\"\n",
    "        subcontracts_soup = soup.select(css_selector)\n",
    "\n",
    "        # Step 3: Loop over the subparts\n",
    "        contract_df = pd.DataFrame(columns= ['Text', 'Link', 'Year', 'subcontract_html', 'subcontract_text'])\n",
    "        subcontracts_loop = subcontracts\n",
    "        subcontract_df = pd.DataFrame(columns=['contract', 'year', 'subcontract_title', 'subcontract_html', 'subcontract_text'])\n",
    "        for subcontract_nr in range(len(subcontracts)):\n",
    "            #print(subcontract_nr)\n",
    "            #load page\n",
    "            driver.get(link)\n",
    "            element=WebDriverWait(driver, 300).until(EC. element_to_be_clickable((By.CLASS_NAME, '_c._d._e._f._h._av._al')))\n",
    "            subcontracts_loop = driver.find_elements(By.XPATH, xpath)\n",
    "\n",
    "            subcontract = subcontracts_loop[subcontract_nr]\n",
    "            # Step 3a: Click on the subpart to load its content\n",
    "            subcontract.click()\n",
    "\n",
    "            # Wait for the page to load \n",
    "            element=WebDriverWait(driver, 300).until(EC. element_to_be_clickable((By.CLASS_NAME, '_c._d._e._f._h._av._al')))\n",
    "\n",
    "            #Step 3b: Scrape the displayed text on the subpart\n",
    "            soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "            #paragraphs = soup.find_all(class_=re.compile(r'\\bcp_digital_para para pr-'))\n",
    "\n",
    "            #print(paragraphs)\n",
    "\n",
    "            #select text of the actual subcontract\n",
    "            actual_subcontract = soup.find(class_=re.compile(r'\\bcp_digital_para cp_digital'))\n",
    "\n",
    "            subcontract_df.loc[subcontract_nr,'contract'] = all_years_df.loc[i,'Text']\n",
    "            subcontract_df.loc[subcontract_nr,'year'] = all_years_df.loc[i,'Year'] \n",
    "            subcontract_df.loc[subcontract_nr,'subcontract_title'] = subcontracts_soup[subcontract_nr].find('a').get_text()\n",
    "            subcontract_df.loc[subcontract_nr,'subcontract_html'] = str(actual_subcontract)\n",
    "            subcontract_df.loc[subcontract_nr, 'subcontract_text'] = actual_subcontract.get_text()\n",
    "\n",
    "\n",
    "        contracts_df = pd.concat([contracts_df, subcontract_df], ignore_index = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "subcontracts_soup = soup.select(css_selector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "contracts_df.to_csv('./data/kv_contracts_all_years.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        KollektivvertragRedaktionelle AnmerkungenQuell...\n",
      "1        KollektivvertragRedaktionelle AnmerkungenQuell...\n",
      "2        KollektivvertragRedaktionelle AnmerkungenQuell...\n",
      "3        KollektivvertragRedaktionelle AnmerkungenQuell...\n",
      "4        KollektivvertragRedaktionelle AnmerkungenQuell...\n",
      "                               ...                        \n",
      "54661    Zusatzkollektivvertragabgeschlossen am 03.12.2...\n",
      "54662    ZusatzkollektivvertragRedaktionelle Anmerkunge...\n",
      "54663    ZusatzkollektivvertragRedaktionelle Anmerkunge...\n",
      "54664    ZusatzkollektivvertragRedaktionelle Anmerkunge...\n",
      "54665    ZusatzkollektivvertragRedaktionelle Anmerkunge...\n",
      "Name: subcontract_text, Length: 54666, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(contracts_df['subcontract_text'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cb_scraping",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
